{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from random import sample\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "from datasets import load_from_disk, Dataset, concatenate_datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils import post_process_generated_cell_sentences, convert_cell_sentence_back_to_expression_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_adata = anndata.read_h5ad(\"/home/sr2464/Desktop/cell2sentence-ft/preprocessed_adata.h5ad\")\n",
    "processed_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_from_disk(\"cell_sentence_arrow_ds/train_arrow_ds\")\n",
    "val_ds = load_from_disk(\"cell_sentence_arrow_ds/val_arrow_ds\")\n",
    "test_ds = load_from_disk(\"cell_sentence_arrow_ds/test_arrow_ds\")\n",
    "\n",
    "total_ds = concatenate_datasets([train_ds, val_ds, test_ds])\n",
    "total_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder processed adata rows to matcha arrow dataset\n",
    "train_partition_indices = np.load(\"cell_sentences/train_partition_indices.npy\")\n",
    "val_partition_indices = np.load(\"cell_sentences/val_partition_indices.npy\")\n",
    "test_partition_indices = np.load(\"cell_sentences/test_partition_indices.npy\")\n",
    "\n",
    "all_indices = np.concatenate([train_partition_indices, val_partition_indices, test_partition_indices], axis=0)\n",
    "all_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_adata = processed_adata[all_indices, :].copy()  # Reorders rows\n",
    "processed_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_adata.X = processed_adata.X.toarray()\n",
    "type(processed_adata.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restrict data to first 100 highest expressed genes\n",
    "\n",
    "Restrict cell sentences to first 100 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ds = total_ds.map(lambda example: {\"first_100_gene_words\": example[\"input_ids\"].split(\" \")[:100]})\n",
    "total_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_ds[0][\"first_100_gene_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict expression vectors to top 100 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_idx in range(0, 800, 160):\n",
    "    print(np.count_nonzero(processed_adata.X[cell_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_idx in tqdm(range(processed_adata.X.shape[0])):\n",
    "    cell_expr_vector = processed_adata.X[cell_idx]\n",
    "    hundredth_top_expr_value = np.partition(cell_expr_vector, -100)[-100]\n",
    "    cell_expr_vector[cell_expr_vector <= hundredth_top_expr_value] = 0\n",
    "    processed_adata.X[cell_idx] = cell_expr_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_idx in range(0, 800, 160):\n",
    "    # Slightly less than 100 because many genes might have same expression count and gets filtered out\n",
    "    print(np.count_nonzero(processed_adata.X[cell_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert cell sentences back to expression vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed dataset linear model parameters\n",
    "dataset_df = pd.read_csv(\"transformation_metrics_and_parameters.csv\")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = dataset_df.iloc[0, 2].item()\n",
    "intercept = dataset_df.iloc[0, 3].item()\n",
    "print(f\"slope: {slope:.4f}, intercept: {intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in gene vocabulary\n",
    "global_vocab = set()\n",
    "with open(\"cell_sentences/vocab_human.txt\", \"r\") as fp:\n",
    "    for line in fp:\n",
    "        line = line.rstrip()  # remove end whitespace, e.g. newline\n",
    "        line_elements = line.split(\" \")\n",
    "        gene_name = line_elements[0]\n",
    "        global_vocab.add(gene_name)\n",
    "\n",
    "global_vocab_list = list(global_vocab)\n",
    "global_vocab_list = [gene_name.upper() for gene_name in global_vocab_list]\n",
    "print(len(global_vocab_list))\n",
    "global_vocab_list[30:40:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_sentences_converted_back_to_expression = []\n",
    "for cell_idx in tqdm(range(processed_adata.shape[0])):\n",
    "    cell_sentence_list = total_ds[cell_idx][\"first_100_gene_words\"]\n",
    "    cell_sentence_str = \" \".join(cell_sentence_list)\n",
    "\n",
    "    post_processed_sentence, num_genes_replaced = post_process_generated_cell_sentences(\n",
    "        cell_sentence=cell_sentence_str,\n",
    "        global_dictionary=global_vocab_list,\n",
    "        replace_nonsense_string=\"NOT_A_GENE\",\n",
    "    )\n",
    "\n",
    "    reconstructed_expr_vec = convert_cell_sentence_back_to_expression_vector(\n",
    "        cell_sentence=post_processed_sentence, \n",
    "        global_dictionary=global_vocab_list, \n",
    "        slope=slope, \n",
    "        intercept=intercept\n",
    "    )\n",
    "    all_cell_sentences_converted_back_to_expression.append(reconstructed_expr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_sentences_converted_back_to_expression = np.stack(all_cell_sentences_converted_back_to_expression, dtype=np.float32)\n",
    "all_cell_sentences_converted_back_to_expression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_adata = sc.AnnData(X=all_cell_sentences_converted_back_to_expression)\n",
    "reconstructed_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_adata.obs[\"cell_type_label\"] = total_ds[\"cell_type\"]\n",
    "reconstructed_adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_adata.var.index = global_vocab_list\n",
    "reconstructed_adata.var[\"gene_name\"] = global_vocab_list\n",
    "reconstructed_adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_idx in range(0, 800, 160):\n",
    "    # Slightly less than 100 because many genes might have same expression count and gets filtered out\n",
    "    print(np.count_nonzero(processed_adata.X[cell_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_idx in range(0, 800, 160):\n",
    "    # Slightly less than 100 because many genes might have same expression count and gets filtered out\n",
    "    print(np.count_nonzero(reconstructed_adata.X[cell_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_adata.write_h5ad(\"processed_adata_top100genes.h5ad\")\n",
    "reconstructed_adata.write_h5ad(\"reconstructed_adata_from_cell_sentences_top100genes.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 64-bit ('cell2sentence')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2081a8f405f3958f1130dcbdb81c3dde65c41d32cb522de0d7b483caebdabdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
